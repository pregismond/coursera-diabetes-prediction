{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diabetes Prediction using PySpark MLlib\n",
        "\n",
        "In this project, we will build a logistic regression model to classify between diabetic and the non-diabetic patients. After training the model, we assess its performance using relevant metrics to gauge accuracy and effectiveness. The model is saved for future use, ensuring it can be retrieved and deployed in real-world applications to make predictions on new data.\n",
        "\n",
        "This project has four parts: \n",
        "\n",
        "- Part 1 - Perform ETL Activity\n",
        "  - Load a csv dataset\n",
        "  - Check for null values in each column\n",
        "  - Replace zero values with mean of the column\n",
        "  - Store the cleaned data in parquet format\n",
        "- Part 2 - Build a Logistic Regression Classifier\n",
        "  - Correlation analysis among the input and the output variables\n",
        "  - Selection of the input features\n",
        "  - Split the data into training and test sets\n",
        "  - Build and train the Logistic Regression Model\n",
        "- Part 3 - Evaluate the Model\n",
        "  - Evaluate the model using relevant metrics\n",
        "- Part 4 - Persist the Model\n",
        "  - Save the model for future production use\n",
        "  - Load and verify the stored model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preliminaries: Installing libraries and downloading data\n",
        "\n",
        "Install the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install pyspark\n",
        "! pip install findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clone the required dataset from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! git clone https://github.com/pregismond/diabetes_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if dataset exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! ls diabetes_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing Libraries\n",
        "\n",
        "Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import findspark\n",
        "import warnings\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "\n",
        "# Suppress generated warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "findspark.init()\n",
        "\n",
        "# import functions/Classes for sparkml\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import col, filter, mean, when\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import LogisticRegressionModel\n",
        "\n",
        "# import functions/Classes for metrics\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a spark session\n",
        "\n",
        "Ignore any warnings by SparkSession command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Diabetes Prediction\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5sG3MLXlOews"
      },
      "source": [
        "## Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1 - Perform ETL Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our initial step involves reading the CSV file named `diabetes.csv` into a Spark DataFrame called `diabetes_df`.\n",
        "\n",
        "Load a csv dataset\n",
        "\n",
        "* Using the `spark.read.csv` function we load the data into a dataframe\n",
        "* The `header=True` indicates that there is a header row in our csv file\n",
        "* The `inferSchema=True` tells spark to automatically determine the data types of the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ST1rFFOlOu8s"
      },
      "outputs": [],
      "source": [
        "diabetes_df = spark.read.csv(\"./diabetes_dataset/diabetes.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then display the structure of the `diabetes_df` DataFrame, including details about all columns and their associated data types. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diabetes_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show top 5 rows from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diabetes_df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the dimensions of the dataframe (rows, columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print((diabetes_df.count(), len(diabetes_df.columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the value counts for the column `Outcome`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kpZlF2S2Ovgw"
      },
      "outputs": [],
      "source": [
        "diabetes_df.groupBy(\"Outcome\") \\\n",
        "    .count().withColumnRenamed(\"count\", \"Count\") \\\n",
        "    .sort(\"Count\", ascending=False) \\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Outcome` column consists of two classes, each indicating whether a patient has diabetes or not:\n",
        "\n",
        "* **0**: the patient does not have diabetes\n",
        "* **1**: the patient has diabetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can generate descriptive statistics to view some basic statistical details like count, mean, standard deviation, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NewCNZEMOvtM"
      },
      "outputs": [],
      "source": [
        "diabetes_df.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see above, the minimum values for the `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, and `BMI` columns are 0, which is an invalid reading. We will replace the zero values in these five columns with their respective mean values. However, before doing so, let’s check for any null or missing values in the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for null values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in diabetes_df.columns:\n",
        "    null_count = diabetes_df[diabetes_df[column].isNull()].count()\n",
        "    print(f\"{column}: {null_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, we do not have any missing values for any of the columns present in our dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace zero values with mean of the column\n",
        "\n",
        "* Replace zero values for the 5 columns from Glucose to BMI with their respective mean values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_list = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
        "\n",
        "# Replace zero values with mean of the column\n",
        "for column in columns_list:\n",
        "    # Count zero values in the column\n",
        "    zero_count = diabetes_df.filter(col(column) == 0).count()\n",
        "    \n",
        "    # Calculate mean value of the column and convert to integer\n",
        "    mean_value = int(diabetes_df.select(mean(col(column))).collect()[0][0])\n",
        "    \n",
        "    # Replace zero values with mean value\n",
        "    print(f\"Zero values in {column}: {zero_count}, Mean value: {mean_value}\")\n",
        "    diabetes_df = diabetes_df.withColumn(column, when(col(column) == 0, mean_value).otherwise(col(column)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the dataframe contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "C0bk0Ps_PFwk"
      },
      "outputs": [],
      "source": [
        "diabetes_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store the cleaned data in parquet format\n",
        "\n",
        "* Save the dataframe as `diabetes_cleaned.parquet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diabetes_df.write.mode(\"overwrite\").parquet(\"diabetes_cleaned.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify that the parquet file(s) are created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! ls -l diabetes_cleaned.parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2 - Build a Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, load data from \"diabetes_cleaned.parquet\" into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diabetes_df = spark.read.parquet(\"diabetes_cleaned.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show total number of rows in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(diabetes_df.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Determine the correlation among the set of input and output variables\n",
        "\n",
        "* Correlation is the statistical relationship between two variables, where a change in one variable results in a change in the other.\n",
        "    * input variables are the columns from `Pregnancies` to `Age`\n",
        "    * output variable is the `Outcome` column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in diabetes_df.columns:\n",
        "    print(f\"Correlation to Outcome for {column} is {diabetes_df.stat.corr('Outcome', column)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As observed above, the Glucose column has the highest correlation value at 0.48, while all other values are below 0.4. This indicates that there are no highly correlated variables. Therefore, we will retain all the input columns as features for the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define `features` selection using VectorAssembler\n",
        "\n",
        "* Assemble the input columns into a single vector column `features`\n",
        "* Use all the columns except `Outcome` as input features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Fl7Edj-OQACn"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"Pregnancies\",\n",
        "        \"Glucose\",\n",
        "        \"BloodPressure\",\n",
        "        \"SkinThickness\",\n",
        "        \"Insulin\",\n",
        "        \"BMI\",\n",
        "        \"DiabetesPedigreeFunction\",\n",
        "        \"Age\"\n",
        "    ],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "diabetes_transformed_df = assembler.transform(diabetes_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a new DataFrame `diabetes_final_df` using the existing `diabetes_transformed_df` DataFrame.\n",
        "* Select only the `features` and `Outcome` columns to isolate the relevant data needed for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F89--FiVQQJn"
      },
      "outputs": [],
      "source": [
        "diabetes_final_df = diabetes_transformed_df.select(\"features\",\"Outcome\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the structure of the `diabetes_final_df` DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cKpm5912Qji_"
      },
      "outputs": [],
      "source": [
        "diabetes_final_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the dataframe contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diabetes_final_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split the data into training and test sets\n",
        "\n",
        "* We split the data set in the ratio of 70:30. 70% training data, 30% testing data.\n",
        "* The random_state variable `seed` controls the shuffling applied to the data before applying the split. Pass the same integer for reproducible output across multiple function calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(trainingData, testingData) = diabetes_final_df.randomSplit([0.7, 0.3], seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a logistic regression model\n",
        "\n",
        "* Logistic Regression gives the highest performance for binary classification models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "r_Nom7aZQjuN"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression(labelCol=\"Outcome\")\n",
        "model = lr.fit(trainingData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display a summary of the trained model, including descriptive statistics of the model's predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OljO2HcIQj7E"
      },
      "outputs": [],
      "source": [
        "summary = model.summary\n",
        "summary.predictions.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DfaD_vzfQkah"
      },
      "source": [
        "### Part 3 - Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After training the model, we will assess its accuracy and effectiveness using suitable metrics.\n",
        "\n",
        "Make predictions on testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CHC5Erq7Q4QN"
      },
      "outputs": [],
      "source": [
        "predictions = model.evaluate(testingData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UBltVqoNQ4cM"
      },
      "outputs": [],
      "source": [
        "predictions.predictions.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, `LogisticRegression` has added three additional columns as predictions:\n",
        "\n",
        "- **rawPrediction**: This is the raw prediction for each possible label and represents the raw output of the logistic regression classifier.\n",
        "- **probability**: This is the result of applying logistic regression to this raw prediction.\n",
        "- **prediction**: This is the corresponding class label that the model has predicted.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the `BinaryClassificationEvaluator` to evaluate the overall performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "A4BHCxCiQ4l-"
      },
      "outputs": [],
      "source": [
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Outcome\")\n",
        "accuracy = evaluator.evaluate(model.transform(testingData))\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 4 - Persist the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the model for future use, ensuring that it can be stored and retrieved later. This allows us to deploy the trained model in real-world applications and make predictions on new data.\n",
        "\n",
        "* Save the model as \"diabetes_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create folder to save model\n",
        "! mkdir -p diabetes_model\n",
        "\n",
        "# Persist the model to the path \"./diabetes_model/\"\n",
        "model.write().overwrite().save(\"./diabetes_model/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the model from the folder \"diabetes_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4zSA9_KCQ47W"
      },
      "outputs": [],
      "source": [
        "loaded_model = LogisticRegressionModel.load(\"./diabetes_model/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the csv file named `new_test.csv` into a Spark DataFrame called `new_test_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MBq2hq27RdHB"
      },
      "outputs": [],
      "source": [
        "new_test_df = spark.read.csv(\"./diabetes_dataset/new_test.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the structure of the `new_test_df` DataFrame, including details about all columns and their associated data types. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "co8K0NZsRdQB"
      },
      "outputs": [],
      "source": [
        "new_test_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we can see that we have similar input features as before. However, one thing to notice is that we don't have the output column `Outcome` because this dataset is unlabelled. We'll use the loaded model to predict diabetes on this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assemble the input columns into a single vector column `features`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "J7jtGf4lRdaz"
      },
      "outputs": [],
      "source": [
        "new_test_transformed_df = assembler.transform(new_test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the structure of the `new_test_transformed_df` DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kd1glzOnRdkq"
      },
      "outputs": [],
      "source": [
        "new_test_transformed_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we have an additional `features` column as a vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use `loaded_model` to make predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "40Dck7K_Rdxh"
      },
      "outputs": [],
      "source": [
        "predictions = loaded_model.transform(new_test_transformed_df)\n",
        "predictions.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we got an additional 3 columns: `rawPrediction`, `probability`, and `prediction`. The `prediction` column contains the main class level as either 0 or 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the predictions\n",
        "\n",
        "* Display only the `features` column and `prediction`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AHpfS2SjRd7s"
      },
      "outputs": [],
      "source": [
        "predictions.select(\"features\",\"prediction\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a total of four input features, and our model has made certain predictions on the input data. A prediction of 1 indicates that a patient is diabetic, while a prediction of 0 indicates that a patient is a non-diabetic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stop Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Change Log\n",
        "\n",
        "\n",
        "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
        "|---|---|---|---|\n",
        "| 2024-08-03  | 0.1  | Pravin Regismond | Initial Version |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright © 2024 Pravin Regismond. All rights reserved."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Diabetes_Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
